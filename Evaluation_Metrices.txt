EVALUATION METRICS
	REGRESSION
	CLASSIFICATION 
	CLUSTERING



********************************************************************************************************************************************
-------------------------------------------------------------------------------------------------------------------
REGRESSION EVALUATION METRICS - https://github.com/Gurubux/SelfStudyNotes/tree/master/Linear_Regression
-------------------------------------------------------------------------------------------------------------------
	      							         â‚™
	MAE (Mean Absolute Error) 		=  1/n   Î£ | yáµ¢ - Å· |
		  								    á¶¦â¼Â¹
         							         â‚™
	MSE (Mean Square Error)			=  1/n   Î£ (yáµ¢ - Å· )Â²    =   1/n * RSS
										    á¶¦â¼Â¹
							
	RMSE (Root Mean Square Error)	=  âˆšMSE

	  									â‚™
	RSS (Residual sum of squares)	=	Î£ (yáµ¢ - Å·áµ¢)Â²
									   á¶¦â¼Â¹

	  									â‚™
	TSS (Total sum of squares)		=	Î£ (yáµ¢ - È³)Â²
									   á¶¦â¼Â¹

	   									â‚™
										Î£ | yáµ¢ - Å·áµ¢ |			
									   á¶¦â¼Â¹		
	RAE (Relative Absolute Error)	=  --------------	
									    â‚™
										Î£ | yáµ¢ - È³ |			
									   á¶¦â¼Â¹	

	       								â‚™
										Î£ (yáµ¢ - Å·áµ¢)Â²			
									   á¶¦â¼Â¹						RSS
	RSE (Relative Square Error)		=  --------------    = 	  --------
									    â‚™						TSS
										Î£ (yáµ¢ - È³)Â²
									   á¶¦â¼Â¹	
	
	RÂ² Score  = (Variation(mean) - Variation(Fitted Line)) / Variation(mean) 
			  		( TSS - RSS ) 
			  =    ---------------
					   ( TSS )
			  = 1 - RSS/TSS  
			  = 1 - RSE
	It represents how close the data values are to the fitted regression line.			
	R-squared values, like 0.73, can be translated into percentages by simply multiplying them by 100. An R-squared value of 0.73 means that there is a 73% reduction in variation around a fitted line compared to the mean. If R-squared was 1, then there would be a 100% reduction and if R-squared = 0, there would be a 0% reduction.


	                            ( n - 1 )
    Adj RÂ²    = 1 - (1 - RÂ²) -----------------
                              ( n - p - 1 )


    F-value 
                              
    	TSS = ss_mean = sum((y - np.mean(y))**2)
		RSS = ss_simple = sum((y - reg.predict(X))**2)
		
		
					( TSS - RSS ) (Pð’»áµ¢â‚œ - Pâ‚˜â‚‘â‚â‚™)
		F-value = -------------------------------
					   ( RSS ) (n - Pð’»áµ¢â‚œ)
#https://www.youtube.com/watch?v=nk2CQITm_eo

	P-value
			= 1 - CDF(F-value , DoF1 		   , DoF2 )	
			= 1 - CDF(F-value , Extra Features , (n - Pð’»áµ¢â‚œ) )	
			= 1 - CDF(F-value , (Pð’»áµ¢â‚œ - Pâ‚˜â‚‘â‚â‚™)  , (n - Pð’»áµ¢â‚œ) )	


Pð’»áµ¢â‚œ 	-> Parameters in the regression Line
Pâ‚˜â‚‘â‚â‚™ 	-> All the parameters become 0 except intercept thus Pâ‚˜â‚‘â‚â‚™ is usually 1
n 		-> Number of data points
	
	
	t-stat   =  Coeff / Std Error

	Leverage = 1/n + (xáµ¢ - xÌ„ )/(TSS)

	Influence = Cook`s distance


from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,explained_variance_score,max_error,mean_squared_log_error,median_absolute_error

explained_variance_score(y, predictions)	#Explained variance regression score function
mean_absolute_error(y, predictions)
mean_squared_error(y, predictions)	
r2_score(y, predictions)
max_error(y, predictions)
mean_squared_log_error(y, predictions)
median_absolute_error(y, predictions)
print("summary()\n",est2.summary())
>>>
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.518
Model:                            OLS   Adj. R-squared:                  0.507
Method:                 Least Squares   F-statistic:                     46.27
Date:                Fri, 19 Jul 2019   Prob (F-statistic):           3.83e-62
Time:                        09:01:52   Log-Likelihood:                -2386.0
No. Observations:                 442   AIC:                             4794.
Df Residuals:                     431   BIC:                             4839.
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const        152.1335      2.576     59.061      0.000     147.071     157.196
x1           -10.0122     59.749     -0.168      0.867    -127.448     107.424
x2          -239.8191     61.222     -3.917      0.000    -360.151    -119.488
x3           519.8398     66.534      7.813      0.000     389.069     650.610
x4           324.3904     65.422      4.958      0.000     195.805     452.976
x5          -792.1842    416.684     -1.901      0.058   -1611.169      26.801
x6           476.7458    339.035      1.406      0.160    -189.621    1143.113
x7           101.0446    212.533      0.475      0.635    -316.685     518.774
x8           177.0642    161.476      1.097      0.273    -140.313     494.442
x9           751.2793    171.902      4.370      0.000     413.409    1089.150
x10           67.6254     65.984      1.025      0.306     -62.065     197.316
==============================================================================
Omnibus:                        1.506   Durbin-Watson:                   2.029
Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404
Skew:                           0.017   Prob(JB):                        0.496
Kurtosis:                       2.726   Cond. No.                         227.
==============================================================================
-------------------------------------------------------------------------------------------------------------------
Two types of evaluation approaches that can be used to achieve this goal.These approaches are: 
	1. train and test on the same dataset, and 
	2. train/test split.
	3. K Fold 					
		cross_val_score()
		cross_val_score().mean()
	4. ShuffleSplit()
	cross_val_score(rf_class, data_input, data_output, scoring='accuracy', cv = 10)
	cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)
	cross_val_score(rf_class, data_input, data_output, scoring='accuracy', cv = 10)

********************************************************************************************************************************************	

---------------------------------------------------------------------------------------------------------------------------------------------
				CLASSIFICATION EVALUATION METRICS - https://github.com/Gurubux/SelfStudyNotes/tree/master/Logistic_Regression
---------------------------------------------------------------------------------------------------------------------------------------------
In "classification" problems, we use two types of algorithms (dependent on the kind of output it creates) 
	Class output : Algorithms like SVM and KNN create a class output. For instance, in a binary classification problem, the outputs will be either 0 or 1. However, today we have algorithms which can convert these class outputs to probability. But these algorithms are not well accepted by the statistics community.
	Probability output : Algorithms like Logistic Regression, Random Forest, Gradient Boosting, Adaboost etc. give probability outputs. Converting probability outputs to Class output is just a matter of creating a threshold probability.

In "regression" problems, we do not have such inconsistencies in output. The output is always continuous in nature and requires no further treatment.




SENSITIVITY-SPECIFICITY-PRECISION-ACCURACY CONFUSION MATRIX
 # https://github.com/Gurubux/ML-Analysis-Steps/tree/master/Confusion-Matrix_Sensitivity-Recall_Specificity_Precision_Accuracy

AREA UNDER THE RECEIVER OPERATING CHARACTERISTIC CURVE ( AUC ROC  )
"https://github.com/Gurubux/ML-Analysis-Steps/tree/master/ROC_AUC"








********************************************************************************************************************************************
--------------------------------------------------------------------------------------------------------------------------
REGRESSION and CLASSIFICATION
--------------------------------------------------------------------------------------------------------------------------


CROSS-VALIDATION
"https://github.com/Gurubux/ML-Analysis-Steps/tree/master/Cross-Validation"

GridSearchCV(scoring='')
"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV"

@Scoring							Function											Comment
CLASSIFICATION	 	 
â€˜accuracyâ€™	                        metrics.accuracy_score	 
â€˜balanced_accuracyâ€™	                metrics.balanced_accuracy_score	 
â€˜average_precisionâ€™	                metrics.average_precision_score	 
â€˜brier_score_lossâ€™	                metrics.brier_score_loss	 
â€˜f1â€™	                        	metrics.f1_score									for binary targets
â€˜f1_microâ€™	                        metrics.f1_score									micro-averaged
â€˜f1_macroâ€™	                        metrics.f1_score									macro-averaged
â€˜f1_weightedâ€™	                    metrics.f1_score									weighted average
â€˜f1_samplesâ€™	                    metrics.f1_score									by multilabel sample
â€˜neg_log_lossâ€™	                    metrics.log_loss									requires predict_proba support
â€˜precisionâ€™ etc.	                metrics.precision_score								suffixes apply as with â€˜f1â€™
â€˜recallâ€™ etc.	                    metrics.recall_score								suffixes apply as with â€˜f1â€™
â€˜jaccardâ€™ etc.	                    metrics.jaccard_score								suffixes apply as with â€˜f1â€™
â€˜roc_aucâ€™	                        metrics.roc_auc_score								 

CLUSTERING	 	 
â€˜adjusted_mutual_info_scoreâ€™	    metrics.adjusted_mutual_info_score	 
â€˜adjusted_rand_scoreâ€™	            metrics.adjusted_rand_score	 
â€˜completeness_scoreâ€™	            metrics.completeness_score	 
â€˜fowlkes_mallows_scoreâ€™	            metrics.fowlkes_mallows_score	 
â€˜homogeneity_scoreâ€™	                metrics.homogeneity_score	 
â€˜mutual_info_scoreâ€™	                metrics.mutual_info_score	 
â€˜normalized_mutual_info_scoreâ€™	    metrics.normalized_mutual_info_score	 
â€˜v_measure_scoreâ€™	                metrics.v_measure_score	 

REGRESSION	 	 
â€˜explained_varianceâ€™	            metrics.explained_variance_score	 
â€˜max_errorâ€™	                        metrics.max_error	 
â€˜neg_mean_absolute_errorâ€™	        metrics.mean_absolute_error	 
â€˜neg_mean_squared_errorâ€™	        metrics.mean_squared_error	 
â€˜neg_mean_squared_log_errorâ€™	    metrics.mean_squared_log_error	 
â€˜neg_median_absolute_errorâ€™	        metrics.median_absolute_error	 
â€˜r2â€™	                        	metrics.r2_score	 



